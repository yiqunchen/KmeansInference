<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Technical details • KmeansInference</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet">
<meta property="og:title" content="Technical details">
<meta property="og:description" content="KmeansInference">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">KmeansInference</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/technical_details.html">Technical details</a>
</li>
<li>
  <a href="../articles/Tutorials.html">Software tutorials</a>
</li>
<li>
  <a href="../articles/real_data_example.html">Real data example</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="technical_details_files/header-attrs-2.11/header-attrs.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Technical details</h1>
            
      
      
      <div class="hidden name"><code>technical_details.Rmd</code></div>

    </div>

    
    
<center>
<div class="figure">
<img src="../man/figures/combined_two_d.png" style="width:80.0%" alt=""><p class="caption">Figure 1: (a): The piecewise constant segments of <span class="math inline">\(\beta\)</span>. (b): Both tests based on <span class="math inline">\(p_{\text{Hyun}}\)</span> and <span class="math inline">\(p_{\hat{C}_1,\hat{C}_2}\)</span> control the selective Type I error, but the z-test <span class="math inline">\(p_{\text{Naive}} = \mathbb{P}(|\nu^\top Y|\geq |\nu^\top y|)\)</span> leads to inflated selective Type I error. (c): For a given value of the effect size (<span class="math inline">\(|\nu^\top\beta|/\sigma\)</span>), the test based on <span class="math inline">\(p_{\hat{C}_1,\hat{C}_2}\)</span> has higher power than the test based on <span class="math inline">\(p_{\text{Hyun}}\)</span>. Power for both tests increases as a function of the effect size.</p>
</div>
</center>
<div id="overview" class="section level3">
<h3 class="hasAnchor">
<a href="#overview" class="anchor"></a>Overview</h3>
<p>The graph fused lasso (GFLasso) is widely used to reconstruct signals that are piecewise constant on a graph, meaning that nodes connected by an edge in the graph tend to have identical values. Many special cases of the graph fused lasso have been studied in the literature. For instance, we can consider the one-dimensional chain graph, in which the observations are ordered, and there is an edge between each pair of adjacent observations. This leads to the one-dimensional fused lasso, a well-studied and celebrated method for changepoint detection. When the underlying graph is a two-dimensional grid graph, constructed by connecting each node to its four closest neighbors (up, down, left, right), the graph fused lasso is also known as total-variational denoising.</p>
<p>One desirable property of the graph fused lasso is that we can segment its solution into <em>connected components</em>, that is, sets of elements of the reconstructed signals that share a common value. In this tutorial, we consider testing for a difference in the means across two connected components, estimated using the graph fused lasso. A naive procedure, e.g., a two-sample z-test, will not control the selective Type I error — the probability of falsely rejecting the null hypothesis <em>given that we decided to conduct the test</em> — since the null hypothesis under consideration is itself a function of the same data used for testing.</p>
<p>In our manuscript, we propose a new test for this task that controls the selective Type I error, and conditions on less information than existing approaches, leading to substantially higher power. In addition, we provide a computationally-efficient implementation of the proposed p-value (see Section 3 of our manuscript for details).</p>
</div>
<div id="model-setup" class="section level3">
<h3 class="hasAnchor">
<a href="#model-setup" class="anchor"></a>Model setup</h3>
<p>We consider a vector <span class="math inline">\(Y \in \mathbb{R}^n\)</span>, a noisy realization of the signal <span class="math inline">\(\beta \in \mathbb{R}^n\)</span>, <span class="math display">\[Y_j = \beta_j + \epsilon_j , \quad \epsilon_j \sim_{\text{i.i.d.}} \mathcal{N}(0, \sigma^2), \quad j =1, \ldots, n,\]</span> with known variance <span class="math inline">\(\sigma^2\)</span>. We assume that <span class="math inline">\(\beta\)</span> is <em>piecewise constant</em> on a graph, meaning that the elements of <span class="math inline">\(\beta\)</span> are connected through an undirected graph <span class="math inline">\(G=(V,E)\)</span>, where each <span class="math inline">\(\beta_j\)</span> corresponds to a node, and adjacent elements tend to take on equal values.</p>
</div>
<div id="graph-fused-lasso" class="section level3">
<h3 class="hasAnchor">
<a href="#graph-fused-lasso" class="anchor"></a>Graph fused lasso</h3>
<p>It is natural to estimate <span class="math inline">\(\beta\)</span> by the graph fused lasso, <span class="math display">\[
  \hat{\beta} = \text{argmin}_{\beta \in \mathbb{R}^n} \left\{ \frac{1}{2}\Vert y-\beta\Vert_2^2 +\lambda \sum_{(j,j')\in E}|\beta_j-\beta_{j'}| \right\},
\]</span> where <span class="math inline">\(G=(V,E)\)</span> is the undirected graph, <span class="math inline">\(V=\{1,\ldots,n\}\)</span>, and <span class="math inline">\((j,j') \in E\)</span> indicates that the <span class="math inline">\(j\)</span>th and <span class="math inline">\(j'\)</span>th vertices in the graph are connected by an edge.</p>
<p>For sufficiently large values of the non-negative tuning parameter <span class="math inline">\(\lambda\)</span>, we will have <span class="math inline">\(\hat\beta_j = \hat\beta_{j'}\)</span> for some <span class="math inline">\((j,j') \in E\)</span>. We can segment <span class="math inline">\(\hat\beta\)</span> into <em>connected components</em> — that is, sets of elements of <span class="math inline">\(\hat\beta\)</span> that are connected in the original graph and share a common value.</p>
</div>
<div id="inference-for-the-difference-in-means-of-two-connected-components" class="section level3">
<h3 class="hasAnchor">
<a href="#inference-for-the-difference-in-means-of-two-connected-components" class="anchor"></a>Inference for the difference in means of two connected components</h3>
<p>We consider testing the null hypothesis that the true mean of <span class="math inline">\(\beta\)</span> is the same across two <em>estimated</em> connected components, i.e., <span class="math display">\[  H_0: {\sum_{j \in \hat{C}_1} \beta_j  }/{|\hat{C}_1|  }  =
 { \sum_{j' \in \hat{C}_2} \beta_{j'} }/{   |\hat{C}_2|} \mbox{ versus }  H_1: {\sum_{j \in \hat{C}_1} \beta_j  }/{|\hat{C}_1|  }  \neq
 { \sum_{j' \in \hat{C}_2} \beta_{j'} }/{   |\hat{C}_2|},
\]</span> where <span class="math inline">\(\hat{C}_1\subseteq V\)</span> and <span class="math inline">\(\hat{C}_2\subseteq V\)</span> are two connected components of <span class="math inline">\(\hat\beta\)</span>, with cardinalities <span class="math inline">\(|\hat{C}_1|\)</span> and <span class="math inline">\(|\hat{C}_2|\)</span>. This is equivalent to testing <span class="math inline">\(H_0: \nu^\top \beta = 0\)</span> versus <span class="math inline">\(H_1: \nu^\top \beta \neq 0\)</span>, where <span class="math inline">\(\nu \in \mathbb{R}^n\)</span> is defined as <span class="math display">\[  \nu_{j} =  1_{( j \in \hat{C}_1)} / |\hat{C}_1| -  1_{( j \in \hat{C}_2)}/|\hat{C}_2|\quad j = 1,\ldots,n.\]</span></p>
<p>This results in a challenging problem because we need to account for the process that led us to test this very hypothesis! Drawing from the selective inference literature, Hyun et al. (2018) tackled this problem by proposing the following <span class="math inline">\(p\)</span>-value: <span class="math display">\[p_{\text{Hyun}} = \mathbb{P}_{H_0}\left(|\nu^{\top} Y |\geq |\nu^{\top} y| \;\middle |\; \bigcap_{k=1}^K \left\{ M_k(Y) = M_k(y) \right\}, \Pi_{\nu}^{\perp} Y= \Pi_{\nu}^{\perp} y\right),\]</span> where <span class="math inline">\({M}_k(y)\)</span> is the output of the <span class="math inline">\(k\)</span>th step of the dual-path algorithm (Tibshirani and Taylor 2011); see Hyun et al. (2018) and Section 2 of Chen et al. (2021+) for (i) a summary of the dual path algorithm for the graph fused lasso and (ii) the definition of <span class="math inline">\({M}_k(y)\)</span>. Here, <span class="math inline">\(\Pi_{\nu}^{\perp}\)</span> is an orthogonal projection matrix used to eliminate nuisance parameters. The key insight of Hyun et al. (2018) is that <span class="math inline">\(p_{\text{Hyun}}\)</span> can be recast as the survival function of a <span class="math inline">\(\mathcal{N}(0, \sigma^2||\nu||_2^2)\)</span> random variable, truncated to an interval that can be efficiently computed from the data.</p>
<p>Our paper relies on a simple observation: the <span class="math inline">\(p\)</span>-value <span class="math inline">\(p_{\text{Hyun}}\)</span> conditions on too much information (i.e., it conditions on <em>all</em> of the outputs of the first <span class="math inline">\(K\)</span> steps of the dual-path algorithm). Typically, the contrast vector <span class="math inline">\(\nu\)</span> in <span class="math inline">\(H_0: \nu^{\top} \beta=0\)</span> is constructed using only the pair of connected components of interest. While conditioning on additional information will preserve the selective Type I error control, it will lead to low power in practice.</p>
<p>Building on this observation, in our work, we propose the following <span class="math inline">\(p\)</span>-value: <span class="math display">\[
p_{\hat{C}_1,\hat{C}_2} =  \mathbb{P}_{H_0}\left(|\nu^\top Y |\geq |\nu^\top y|  \;\middle\vert\;  \hat{C}_1(y),  \hat{C}_2(y) \in \mathcal{CC}_K(Y), \Pi_{\nu}^{\perp} Y= \Pi_{\nu}^{\perp} y \right),
\]</span> where <span class="math inline">\(\hat{C}_1,\hat{C}_2\)</span> are two estimated connected components used to construct <span class="math inline">\(\nu\)</span>, and <span class="math inline">\(\mathcal{CC}_K(Y)\)</span> is the set of <em>all</em> connected components after running <span class="math inline">\(K\)</span> steps of the dual path algorithm on the data <span class="math inline">\(Y\)</span>. We show that this <span class="math inline">\(p\)</span>-value for testing <span class="math inline">\(H_0\)</span> can be written as <span class="math display">\[
p_{\hat{C}_1,\hat{C}_2} = \mathbb{P}\left(|\phi|\geq |\nu^\top y| \;\middle\vert\; \hat{C}_1(y),\hat{C}_2(y) \in \mathcal{CC}_K(y'(\phi))\right),
\]</span> where <span class="math inline">\(\phi\sim \mathcal{N}(0,\sigma^2||\nu||_2^2)\)</span>, and <span class="math inline">\(y'(\phi) = \Pi_{\nu}^{\perp}y+\phi\cdot \frac{\nu}{||\nu||_2^2} = y+\left(\frac{\phi-\nu^{\top}y}{||\nu||_2^2}\right)\nu\)</span> can be thought of as a perturbation of the observed data <span class="math inline">\(y\)</span>, along the direction of <span class="math inline">\(\nu\)</span>.</p>
<p>Moreover, defining <span class="math inline">\(\mathcal{S}_{\hat{C}_1,\hat{C}_2}=\{\phi: \hat{C}_1,\hat{C}_2 \in \mathcal{CC}_K(y'(\phi))\}\)</span>, we can express the <span class="math inline">\(p\)</span>-value as <span class="math inline">\(\mathbb{P}\left(|\phi| \geq |\nu^\top y| \;\middle |\; \phi \in \mathcal{S}_{\hat{C}_1,\hat{C}_2} \right)\)</span>. Thus, it suffices to characterize the set <span class="math inline">\(\mathcal{S}_{\hat{C}_1,\hat{C}_2}\)</span>.</p>
<p>However, computing <span class="math inline">\(\mathcal{S}_{\hat{C}_1,\hat{C}_2}\)</span> is a challenging task, because instead of an interval as in the case of Hyun et al. (2018), <span class="math inline">\(\mathcal{S}_{\hat{C}_1,\hat{C}_2}\)</span> is a union of a potentially very large number of intervals. In other words, if we express the set as <span class="math inline">\(\mathcal{S}_{\hat{C}_1,\hat{C}_2} = \bigcup_{i\in\mathcal{I}} (a_i,a_{i+1})\)</span>, then the index set <span class="math inline">\(\mathcal{I}\)</span> could potentially be very large. In our work, we make use of a recent algorithm proposed in Jewell et al. (2019) to characterize the set <span class="math inline">\(\mathcal{S}_{\hat{C}_1,\hat{C}_2}\)</span> efficiently. The key insight is that empirically, only a small subset of the potentially very large number of intervals is relevant to computing <span class="math inline">\(\mathcal{S}_{\hat{C}_1,\hat{C}_2}\)</span>, i.e., the cardinality of the set <span class="math inline">\(\mathcal{I}\)</span> is usually small to moderate. Moreover, the set <span class="math inline">\(\mathcal{I}\)</span> can be computed with an efficient line search algorithm.</p>
<p>Our software implements an efficient calculation of <span class="math inline">\(p_{\hat{C}_1,\hat{C}_2}\)</span>. We demonstrate that the resulting test has higher power than that based on <span class="math inline">\(p_{\text{Hyun}}\)</span>, while still preserving the selective Type I error control. Additional details and other extensions can be found in Sections 3 and 4 of our paper (Chen et al. 2021+).</p>
</div>
<div id="extensions" class="section level3">
<h3 class="hasAnchor">
<a href="#extensions" class="anchor"></a>Extensions</h3>
<p>Our software also allows for the following extensions:</p>
<ol style="list-style-type: decimal">
<li>Generate <span class="math inline">\((1-\alpha)\)</span> selective confidence intervals for the parameter <span class="math inline">\(\nu^\top \beta\)</span>, the difference in means across two connected components.</li>
<li>An alternative conditioning set parameterized by the number of connected components in the graph fused lasso solution (as opposed to K, the number of steps for the dual path algorithm).</li>
</ol>
</div>
<div id="references" class="section level3">
<h3 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h3>
<p>Chen YT, Jewell SW, Witten DM. (2022+) More powerful selective inference for the graph fused lasso. arXiv preprint. <a href="https://arxiv.org/abs/2109.10451" class="uri">https://arxiv.org/abs/2109.10451</a>.</p>
<p>Fithian W, Sun D, Taylor J. (2014) Optimal Inference After Model Selection. arXiv:1410.2597 [mathST].</p>
<p>Hyun S, G’Sell M, Tibshirani RJ. (2018) Exact post-selection inference for the generalized lasso path. Electron J Stat.</p>
<p>Jewell SW, Fearnhead P, Witten DM. Testing for a Change in Mean After Changepoint Detection. To appear in JRSSB.</p>
<p>Lee J, Sun D, Sun Y, Taylor J. Exact post-selection inference, with application to the lasso. Ann Stat. 2016;44(3):907-927. <a href="doi:10.1214/15-AOS1371" class="uri">doi:10.1214/15-AOS1371</a></p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Yiqun Chen.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
